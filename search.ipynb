{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663270c2-ab2d-42b0-afd8-f05506eded3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/wanglei/anaconda3/envs/wanglei/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home2/wanglei/anaconda3/envs/wanglei/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "2024-07-04 15:40:29,221\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-04 15:40:29 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='/home2/wanglei/Project/model/pythia2.8b_choose', tokenizer='/home2/wanglei/Project/model/pythia2.8b_choose', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-04 15:40:32 selector.py:40] Cannot use FlashAttention backend for Volta and Turing GPUs.\n",
      "INFO 07-04 15:40:32 selector.py:25] Using XFormers backend.\n",
      "INFO 07-04 15:40:36 model_runner.py:104] Loading model weights took 5.1857 GB\n",
      "INFO 07-04 15:40:36 gpu_executor.py:94] # GPU blocks: 552, # CPU blocks: 819\n",
      "INFO 07-04 15:40:38 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 07-04 15:40:38 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 07-04 15:40:42 model_runner.py:867] Graph capturing finished in 4 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import subprocess\n",
    "\n",
    "import timeit\n",
    "import select\n",
    "import json\n",
    "from Lean4Gym import Lean4Gym, ProofState\n",
    "# print(torch.__version__)\n",
    "from torch.nn.parallel import DataParallel  \n",
    "# torch.cuda.set_device(2)\n",
    "\n",
    "from model import policy_model\n",
    "from model import value_model\n",
    "from trainer import Trainer\n",
    "from mcts import State\n",
    "from mcts import Node\n",
    "from mcts import MCTS\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90883ad-7d37-421b-a3f2-59d191e76d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"/home2/wanglei/Project/model/pythia2.8b_choose\"\n",
    "tokenizer = transformers.GPTNeoXTokenizerFast.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20372810-b55c-4140-9ff3-49dd210e0ecf",
   "metadata": {},
   "source": [
    "参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a15c7ec-156f-4b6b-a318-35ecfbe2aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu') \n",
    "\n",
    "args = {\n",
    "    \n",
    "    'batch_size': 4,\n",
    "    'numIters': 10,                                # Total number of training iterations\n",
    "    'num_simulations': 100,                         # Total number of MCTS simulations to run when deciding on a move to play\n",
    "    'numEps': 20,                                  # Number of full games (episodes) to run during each iteration\n",
    "    'numItersForTrainExamplesHistory': 20,\n",
    "    'epochs': 10,                                    # Number of epochs of training per iteration\n",
    "    'checkpoint_path': 'latest.pth',                 # location to save latest set of weights\n",
    "    'TACRIC_NUMBER': 8,\n",
    "    'feature_size':100\n",
    "    # 'MAX_ROUND_NUMBER' : 10\n",
    "}\n",
    "\n",
    "feature_size = args['feature_size']  # 特征向量的size\n",
    "time_out = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3b0cf-ed8b-415c-9033-db9226be8dd0",
   "metadata": {},
   "source": [
    "导入训练好的策略网络和价值网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7fb362-bade-4e17-9fd0-cebdc9b9d1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policyModel = policy_model(feature_size*2, device).to(device)\n",
    "valueModel = value_model(feature_size, device).to(device)\n",
    "\n",
    "checkpoint_policy = torch.load(\"/home2/wanglei/Project/alphazero_leanrepl_gpu/policy_model\")\n",
    "policyModel.load_state_dict(checkpoint_policy['state_dict'])\n",
    "\n",
    "checkpoint_value = torch.load(\"//home2/wanglei/Project/alphazero_leanrepl_gpu/value_model\")\n",
    "valueModel.load_state_dict(checkpoint_value['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5cde4d-80fb-4d7d-986f-16292817925c",
   "metadata": {},
   "source": [
    "导入待证明定理：$ 𝐶_n^{n−k}=𝐶_n^k   (k ≤ n) $ ,获取该定理状态并设置为根节点:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a053dc-ac91-4e7f-947f-7d0a01736e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lean_workdir = \"/home2/wanglei/Project\" # Lean工程的根目录\n",
    "lean_file = \"demo.lean\"   # 待证明定理的Lean文件\n",
    "lean = Lean4Gym(lean_workdir, lean_file)\n",
    "state = lean.getInitState()\n",
    "init_state = State(state)\n",
    "node = Node()\n",
    "node.set_state(init_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d11100c4-8860-4205-a741-0a89a3ca4a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始搜索策略\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: 8480346000156, Q/N: 0.0/0, state: <mcts.State object at 0x7b67c02cbb20>\n",
      "成功策略：\n",
      "成功路径策略：\n",
      "rw [choose_eq_factorial_div_factorial hk]\n",
      "rw [choose_eq_factorial_div_factorial]\n",
      "rw [Nat.sub_sub_self hk]\n",
      "rw [mul_comm]\n",
      "exact Nat.sub_le _ _\n",
      "成功路径状态：\n",
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ Nat.choose n (n - k) = Nat.choose n k\n",
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ Nat.choose n (n - k) = n ! / (k ! * (n - k)!)\n",
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ n ! / ((n - k)! * (n - (n - k))!) = n ! / (k ! * (n - k)!)\n",
      "\n",
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ n - k ≤ n\n",
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ n ! / ((n - k)! * k !) = n ! / (k ! * (n - k)!)\n",
      "\n",
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ n - k ≤ n\n",
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ n - k ≤ n\n",
      "no goals\n",
      "所用时间：True\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "print(\"开始搜索策略\")\n",
    "mcts = MCTS(node, policyModel, valueModel, args, device)\n",
    "timespend = mcts.runmcts(lean, time_out)\n",
    "\n",
    "end = timeit.default_timer()\n",
    "\n",
    "print (\"所用时间：{}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9df09ad4-7bd3-4ef5-9a5a-e00c2382a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ Nat.choose n (n - k) = n ! / (k ! * (n - k)!)\n"
     ]
    }
   ],
   "source": [
    "state1 = lean.run_tactic(state, [\" rw[choose_eq_factorial_div_factorial hk]\"])\n",
    "print(state1.tacticState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "369ba1ac-c5ec-48c3-a155-230b102155c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ n ! / ((n - k)! * (n - (n - k))!) = n ! / (k ! * (n - k)!)\n",
      "\n",
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ n - k ≤ n\n"
     ]
    }
   ],
   "source": [
    "state2 = lean.run_tactic(state1, [\"rw[choose_eq_factorial_div_factorial]\"])\n",
    "print(state2.tacticState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63eadad8-3952-42ca-a849-c72bc6436278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ n ! / ((n - k)! * k !) = n ! / (k ! * (n - k)!)\n",
      "\n",
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ n - k ≤ n\n"
     ]
    }
   ],
   "source": [
    "state3 = lean.run_tactic(state2, [\"rw[Nat.sub_sub_self hk]\"])\n",
    "print(state3.tacticState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd98b354-f375-4aec-a5f9-9ead13c7a3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n k : ℕ\n",
      "hk : k ≤ n\n",
      "⊢ n - k ≤ n\n"
     ]
    }
   ],
   "source": [
    "state4 = lean.run_tactic(state3, [\"rw [mul_comm]\"])\n",
    "print(state4.tacticState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc602f1-6384-4b54-9cf8-ac01a30a75af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no goals\n"
     ]
    }
   ],
   "source": [
    "state5 = lean.run_tactic(state4, [\"exact Nat.sub_le _ _\"])\n",
    "print(state5.tacticState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356ef0c-cffe-4bd5-b913-4dff78b37947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
